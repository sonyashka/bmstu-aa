\chapter{Аналитический раздел}

В данном разделе будут представлены описания алгоритмов поиска расстояний Левенштейна и Дамерау-Левенштейна.

\section{Расстояние Левенштейна}

Редакторским расстоянием или расстоянием Левенштейна \cite{Lev} называется минимальное количество операций, необходимых для преобразования одной строки в другую. Множество операций состоит из вставки (I), удаления (D) и замены символов (R). Для каждой операции введен так называемый штраф (цена), равный 1. Также существет операция совпадение (M), оцениваемая нулевым штрафом. Суть алгоритма заключается в поиске такой последовательности операций, которая оценится минимальным штрафом.

\section{Алгоритм с кэшем в форме двух строк}

Расчет будем вести по рекуррентной формуле через расстояние между подстроками. Положим, что s1[1..i] - подстрока s1 длинной i, s2[1..j] - подстрока s2 длинной j. Тогда

\begin{equation}
	D(s1[1..i], s2[1..j]) = 
	\begin{cases}
		0, i = 0, j = 0 & (D("",""))\\
		j, i = 0, j > 0 & (I)\\
		i, i > 0, j = 0 & (D)\\
		\alpha(s1, s2) \\
	\end{cases}
\end{equation}

где:

\begin{equation}
	\alpha(s1, s2) = min 
	\begin{cases}
		D(s1[1..i], s2[1..j - 1]) + 1 & (I) \\
		D(s1[1..i - 1], s2[1..j]) + 1 & (D) \\
		D(s1[1..i - 1], s2[1..j - 1]) + 
		\begin{cases}
			0, \text{если s1[i] = s2[j]} & (M) \\
			1, \text{иначе} & (R) \\
		\end{cases}
	\end{cases}
\end{equation}

Исходя из данной рекуррентной формулы, мы можем составить матрицу, которая будет хранить ранее просчитанные варианты, однако объем используемой памяти можно сократить, если использовать не матрицу, а две строки. Всего при наличии двух строк мы сможем обращаться к результатам вычислений соседних подстрок, а значит мы сможем рассчитать нужное нам расстояние.

\section{Рекурсивный алгоритм без кэша}

Суть рекурсивного алгоритма заключается в том, что каждый раз при обработке основных строк s1[1..i] и s2[1..j] мы вызываем алгоритм для обработки трех вариантов изменения строк: D(s1[1..i - 1], s2[1..j]), D(s1[1..i - 1], s2[1..j - 1]), D(s1[1..i], s2[1..j - 1]).

Однако у данного варианта есть значительный недостаток - повторные вычисления. Каждый вызов будет обрабатываться индивидуально, а значит для одинаковых входных параметров пересчет будет вестись снова и снова. Чтобы избавиться от многократного определения расстояния можно использовать кэш. 

\section{Рекурсивный алгоритм с кэшем в форме матрицы}

В отличие от предыдущего алгоритма, мы создаем матрицу, все элементы которой изначально инициализируем бесконечностью. Тогда в случае вычисления расстояния для какой-либо из подстрок, мы сможем сохранить значение. Таким образом, если элемент матрицы будет равен бесконечности - он еще не рассчитан, а значит это действие необходимо выполнить; в обратном случае будет возвращен данный элемент.

\section{Расстояние Дамерау - Левенштейна без кэша}

В отличие от расстояния Левенштейна при поиске расстояния Дамерау-Левенштейна \cite{DamLev} ко множеству операций добавляется транспозиция (T) или по-другому обмен (X). Штраф для данной операции также будем считать за 1. Благодаря тому, что можно использовать перестановку 2-х соседних символов, редакционное расстояние может оказаться меньше. Если s1[i - 2] = s2[j - 1] и s1[i - 1] = s2[j - 2], формула (1.2) примет вид:

\begin{equation}
	\alpha(s1, s2) = min 
	\begin{cases}
		D(s1[1..i], s2[1..j - 1]) + 1 & (I) \\
		D(s1[1..i - 1], s2[1..j]) + 1 & (D) \\
		D(s1[1..i - 1], s2[1..j - 1]) + 
		\begin{cases}
			0, \text{если s1[i] = s2[j]} & (M) \\
			1, \text{иначе} & (R) \\
		\end{cases}\\
		D(s1[1..i - 2], s2[1..j - 2]) + 1 & (T)\\
	\end{cases}
\end{equation}

\section{Вывод}

Все формулы подсчета редакционного расстояния рекурентны, реализовать их можно как итерационно, так и рекурсивно.
